{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaceP3Q3Gbs_"
   },
   "source": [
    "***\n",
    "\n",
    "Profesor: Gonzalo A. Ruz, PhD\n",
    "\n",
    "Curso: Aprendizaje Automático\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T19:07:27.439010Z",
     "start_time": "2022-10-04T19:07:25.865850Z"
    },
    "id": "nNRMuddhF9OM"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Global imports and settings\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing Keras\u001b[39m\u001b[38;5;124m\"\u001b[39m,keras\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "# Global imports and settings\n",
    "import keras\n",
    "import tensorflow\n",
    "print(\"Using Keras\",keras.__version__)\n",
    "print(\"Using Tensorflow\",tensorflow.__version__)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T19:07:27.741188Z",
     "start_time": "2022-10-04T19:07:27.708849Z"
    },
    "id": "6w1-_9A6GPlZ"
   },
   "outputs": [],
   "source": [
    "# Silence warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTUf_ss3FMc8"
   },
   "source": [
    "# Clase: Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Cj5Iq_TFMc-"
   },
   "source": [
    "## Fundamentos matemáticos\n",
    "* Un primer ejemplo\n",
    "* Tensores y operaciones con tensores\n",
    "* Backpropagation y descenso de gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egpufCBSFMc-"
   },
   "source": [
    "### Un primer ejemplo: clasificar dígitos\n",
    "- Este ejemplo está destinado a presentar los conceptos principales. Los cubriremos con más detalle más adelante\n",
    "- El conjunto de datos [MNIST](https://en.wikipedia.org/wiki/MNIST_database) contiene imágenes de 28x28 píxeles de dígitos escritos a mano (0-9)\n",
    "- El objetivo es clasificar cada imagen como uno de los posibles dígitos\n",
    "- Son 70000 imagenes\n",
    "- Keras ya trae una partición de entrenmiento (60000) y prueba (10000). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T19:12:19.917187Z",
     "start_time": "2022-10-04T19:12:19.889194Z"
    }
   },
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T19:12:19.588242Z",
     "start_time": "2022-10-04T19:11:48.931318Z"
    },
    "id": "sSHposelFMc_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 16:11:49.079761: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T19:12:20.250021Z",
     "start_time": "2022-10-04T19:12:20.224225Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1YklWYWLFMdA",
    "outputId": "772dcd63-b3e8-43ca-c354-d8a0508025c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "id": "2iNjVoAsFMdA",
    "outputId": "5419b23c-b323-42ff-b6c2-0ef0903cf56f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take some random examples\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "fig, axes = plt.subplots(1, 5,  figsize=(10, 5))\n",
    "for i in range(5):\n",
    "    n = randint(0,60000)\n",
    "    axes[i].imshow(X_train[n], cmap=plt.cm.gray_r)\n",
    "    axes[i].set_xlabel(\"Label: {}\".format(y_train[n]))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ukgXS8IFMdB"
   },
   "source": [
    "#### Redes neuronales\n",
    "* La pieza central de una red neuronal es la _capa_\n",
    "* Puede pensar en ella como un _filtro_ para los datos\n",
    "    - Los datos entran y salen en una forma más útil\n",
    "* Las capas extraen nuevas _representaciones_ de los datos\n",
    "* Los modelos de _Deep learning_ contienen muchas de estas capas\n",
    "    - *Destilan* (refinan) progresivamente los datos\n",
    "\n",
    "![](https://drive.google.com/uc?id=1yBbnQmh3M5r2VJdD4C0mBT1CvvTLpojZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VR392Z1lFMdC"
   },
   "source": [
    "* Los valores de los píxeles se envían a _nodos_ individuales de la _capa de entrada_ (amarillo)\n",
    "* Luego, los datos pasan a través de una o más _capas ocultas_ (azul)\n",
    "    - Un tipo de capa es la capa _densa_ (dense) o _completamente conectada_ (fully connected)\n",
    "    - Cada nodo está conectado a todos los nodos de las capas anteriores y posteriores.\n",
    "* La _capa de salida_ tiene un nodo para cada resultado posible (dígitos 0-9) (naranjo)\n",
    "    - I.e. El primer nodo devuelve la probabilidad de que la imagen de entrada represente un '0'\n",
    "\n",
    "![](https://drive.google.com/uc?id=1CKXgAVeeDw1YITEmIjbRhOxtRwmI5xyL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_e-ef80FMdD"
   },
   "source": [
    "#### El perceptrón\n",
    "* En su forma más simple, cada nodo genera (*outputs*) una suma ponderada de las entradas (*inputs*): $y = \\sum_{i} x_{i}w_i + b$\n",
    "* Necesita aprender el conjunto óptimo de pesos para producir el resultado correcto\n",
    "    * _Bias_ $b$:modelado como el peso de una entrada adicional que siempre está prendida, i.e., '1'\n",
    "* Esto es lo mismo que un modelo lineal, solo puede aprender fronteras de decisión lineales.\n",
    "    * Incluso una red neuronal profunda de perceptrones solo puede aprender un modelo lineal\n",
    "\n",
    "![](https://drive.google.com/uc?id=1mbFczEOoP3E7uwea09LJVmsG2H9Mxsl7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wqtk3IxEFMdD"
   },
   "source": [
    "#### Funciones de activación\n",
    "* Para aprender un modelo no lineal, cada nodo oculto tiene que generar una *función de activación* $f$ no lineal en la suma ponderada de las entradas: $h(x)=f(W_1 x+b_1)$\n",
    "* Asimismo, los nodos de salida usan una función de activación $g$ en las salidas ponderadas de la capa anterior: $o(x)=g(W_2 h(x)+b_2)$\n",
    "\n",
    "![](https://drive.google.com/uc?id=1BL0s6Zc075j3yPndY0WBV3TG03-fPq6C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dz6Zw58fFMdE"
   },
   "source": [
    "#### Funciones de activación\n",
    "* Para los nodos ocultos, las opciones populares son _rectified linear unit_ (ReLU) y _tanh_\n",
    "    - Hay muchas otras. ¡Volveremos a esto pronto!\n",
    "    - ReLU Es muy barato de calcular, acelera el entrenamiento\n",
    "* Para la clasificación, utilizamos *softmax* (o *sigmoid*)\n",
    "    - Transforma la entrada en una probabilidad para cada resultado específico\n",
    "    - Esto es exactamente lo que usamos para la regresión logística!\n",
    "\n",
    "![](https://drive.google.com/uc?id=1KO1NWlpRTDAdRSB4fd-0KhRltXHuEveA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "id": "s-sgYZw8FMdE"
   },
   "source": [
    "Ahora podemos construir una red neuronal simple para MNIST:\n",
    "* Una capa de ReLU oculta densa con 512 nodos\n",
    "    - Entrada de una matriz de 28x28\n",
    "* Capa de salida softmax con 10 nodos\n",
    "\n",
    "``` python\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T19:32:09.806795Z",
     "start_time": "2022-10-04T19:32:09.745955Z"
    },
    "hide_input": false,
    "id": "cOieslu2FMdE"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "network = models.Sequential() #hay qye importar la función models y luego layers, \n",
    "#en este caso la red se llama network\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,))) #primera capa oculta, en este caso\n",
    "#layers.dense\n",
    "\n",
    "#como tenemos 784 entradas y 512 neuronas, es igual a 784*512 = 401408 + 512 = (401920)\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "#la salida de la capa oculta 512 tiene que conectarse a las 10 (salidas), pero tengo que agregar una neurona\n",
    "# de salida : 5120 (512*10) + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhMULovaFMdF"
   },
   "source": [
    "'Visualice' el modelo usando `summary()` \n",
    "- También muestra el número de parámetros del modelo (pesos) que deben aprenderse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T19:32:16.708729Z",
     "start_time": "2022-10-04T19:32:16.614966Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JlVjUpQLFMdF",
    "outputId": "e9c007ab-da9a-4021-e775-b2d4d44100f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "network.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAgeBCoAFMdF"
   },
   "source": [
    "#### Compilación\n",
    "Todavía necesitamos especificar cómo queremos que se entrene la red:\n",
    "* __Loss function__: La función objetivo utilizada para medir qué tan bien está funcionando el modelo y dirigirse en la dirección correcta\n",
    "    - e.g. Cross Entropy (_negative log likelihood_ o _log loss_) para clasificación\n",
    "* __Optimizer__: Cómo optimizar los pesos del modelo en cada iteración.\n",
    "    - usualmente una [variación de stochastic gradient descent](https://arxiv.org/pdf/1609.04747.pdf)\n",
    "* __Metrics__ para monitorear el rendimiento durante el entrenamiento y las prueba.\n",
    "    - ej. accuracy\n",
    "    \n",
    "``` python\n",
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy', #en este caso utilizamos categorical_crossentropy para multiclass\n",
    "                metrics=['accuracy'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T19:36:51.187407Z",
     "start_time": "2022-10-04T19:36:51.133245Z"
    },
    "id": "0bcO_zb8FMdG"
   },
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oL7tH4T5FMdG"
   },
   "source": [
    "#### Pre procesamiento\n",
    "* Las redes neuronales son sensibles al escalado, así que siempre escale las entradas\n",
    "* La red espera los datos en forma (n, 28 * 28), por lo que también necesitamos remodelar (reshape)\n",
    "* También necesitamos codificar categóricamente las etiquetas\n",
    "    - ej. '4' pasa ha ser [0,0,0,0,1,0,0,0,0,0]\n",
    "\n",
    "``` python\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T19:41:25.176680Z",
     "start_time": "2022-10-04T19:41:24.654007Z"
    },
    "id": "VKHrW3wWFMdG"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((60000, 28 * 28))\n",
    "X_test = X_test.reshape((10000, 28 * 28))\n",
    "\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImUx0gZSFMdG"
   },
   "source": [
    "#### Entrenamiento\n",
    "El entrenamiento (fitting) se hace por __stochastic gradient descent__ (SGD).\n",
    "* Optimiza los parámetros del modelo (pesos)\n",
    "* Volveremos a esto pronto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T19:44:10.598011Z",
     "start_time": "2022-10-04T19:43:28.294765Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6SGtiVDgFMdH",
    "outputId": "8e8d5c1e-d6a1-4bc3-bef0-77ae23ae2e3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 7s 12ms/step - loss: 0.2599 - accuracy: 0.9247\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.1039 - accuracy: 0.9694\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 5s 11ms/step - loss: 0.0681 - accuracy: 0.9800\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 6s 14ms/step - loss: 0.0497 - accuracy: 0.9853\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 6s 12ms/step - loss: 0.0381 - accuracy: 0.9888\n"
     ]
    }
   ],
   "source": [
    "network.fit(X_train, y_train, epochs=5, batch_size=128);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJ0mir4TFMdH"
   },
   "source": [
    "#### Predicción\n",
    "Ahora podemos usar `predict` o `predict_proba` para generar predicciones\n",
    "\n",
    "``` python\n",
    "np.set_printoptions(precision=7)\n",
    "print(\"Prediction: \",network.predict(X_test)[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T19:44:12.163277Z",
     "start_time": "2022-10-04T19:44:10.662189Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IAY6dv3xFMdH",
    "outputId": "bd42db93-c373-4cdb-f53d-32ee0c737e68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n",
      "Prediction:  [7.8494518e-09 4.1674247e-11 1.0700379e-06 6.5928725e-05 6.5610174e-12\n",
      " 5.0103026e-08 5.2993087e-15 9.9993193e-01 3.6577518e-08 1.0517269e-06]\n",
      "Label:  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=7)\n",
    "print(\"Prediction: \",network.predict(X_test)[0])\n",
    "print(\"Label: \",y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QypJN1NsFMdH"
   },
   "source": [
    "#### Evaluación\n",
    "Evaluar el modelo entrenado en todo el conjunto de prueba\n",
    "\n",
    "``` python\n",
    "test_loss, test_acc = network.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7DOm1cB5FMdH",
    "outputId": "14d0678c-2dfe-40c5-c782-b7db5c8280da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0803 - accuracy: 0.9802\n",
      "Test accuracy: 0.9801999926567078\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5cJSlmAFMdI"
   },
   "source": [
    "#### Sobreajuste\n",
    "* El accuracy en el conjunto de prueba es un poco más bajo que el accurcay en el conjunto de entrenamiento\n",
    "* Ya hemos visto muchas opciones (piezas móviles) que aún se pueden optimizar:\n",
    "    - Número de capas\n",
    "    - Número de nodos por capa\n",
    "    - Funciones de activación\n",
    "    - Loss function (y los hiperparámetros)\n",
    "    - SGD optimizer (y los hiperparámetros)\n",
    "    - Tamaño del Batch\n",
    "    - Número de épocas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UoZsxY1JFMdI"
   },
   "source": [
    "### Tensores y operaciones con tensores\n",
    "Representando datos y aprendiendo mejores representaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcNPx-IyFMdI"
   },
   "source": [
    "#### Tensores\n",
    "* Un _tensor_ es simplemente una matriz (un arreglo) de n dimensiones (con n ejes)\n",
    "    * 2D tensor: matriz (samples, features)\n",
    "    * 3D tensor: imágenes en niveles de gris (samples, height, width)\n",
    "        - o series de tiempo (samples, timesteps, features)\n",
    "    * 4D tensor: imágenes a color (samples, height, width, channels)\n",
    "    * 5D tensor: video (samples, frames, height, width, channels)  \n",
    "    \n",
    "![](https://drive.google.com/uc?id=1Ik0qtOXMeDmzaslspuuluW-m6_6PFeQS)\n",
    "\n",
    "![](https://drive.google.com/uc?id=1oXLwWvnlgmx3vv3hpZ3Si6IUz6ejEujX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ru0s8n-dFMdI"
   },
   "source": [
    "#### Operaciones con tensores\n",
    "Las operaciones que las capas de la red neuronal realizan en los datos se pueden reducir a unas pocas operaciones tensoriales.\n",
    "\n",
    "``` python\n",
    "keras.layers.Dense(512, activation='relu') \n",
    "```\n",
    "\n",
    "se puede interpretar como una función\n",
    "\n",
    "``` python\n",
    "y = relu(dot(W, x) + b)\n",
    "```\n",
    "\n",
    "* toma un tensor 2D $x$ y devuelve un nuevo tensor 2D $y$\n",
    "* usa un tensor de peso 2D $W$ y un vector de sesgo $b$\n",
    "* realiza un producto punto, suma y $relu(x) = max(x,0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-Q54BQqFMdI"
   },
   "source": [
    "#### Operaciones basadas en elementos (Element-wise operations)\n",
    "\n",
    "ReLU y la suma son operaciones basadas en elementos. Dado que los arreglos numpy admiten operaciones basadas en elementos de forma nativa, estas son simplemente:\n",
    "\n",
    "``` python\n",
    "def relu(x):\n",
    "  return np.maximum(x, 0.)\n",
    "\n",
    "def add(x, y):\n",
    "  return x + y\n",
    "```\n",
    "\n",
    "Nota: si y tiene una dimensión menor que x, será *broadcasted*: ejes se agregan para que coincidan con la dimensionalidad, e y se repite a lo largo de los nuevos ejes \n",
    "\n",
    "``` python\n",
    ">>> np.array([[1,2],[3,4]]) + np.array([10,20])\n",
    "array([[11, 22],\n",
    "       [13, 24]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eKsoqAkFMdJ"
   },
   "source": [
    "#### Tensor dot\n",
    "El producto punto $x . y$ de dos tensores también se puede hacer fácilmente con numpy:\n",
    "``` python \n",
    "z = np.dot(x, y)\n",
    "```\n",
    "donde \n",
    "``` python \n",
    "z[i,j] = x[i,:] * y[:,j]\n",
    "```\n",
    "\n",
    "![](https://drive.google.com/uc?id=1ZRAh_vC6lAulFE3KxenRNh36mh_o0r0V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1h5uJdsFMdJ"
   },
   "source": [
    "#### Interpretación geométrica\n",
    "* Los productos de punto y las adiciones cambian la forma en que los puntos de datos se relacionan entre sí\n",
    "* Nuestro objetivo es encontrar una transformación de los puntos de datos para que sea fácil:\n",
    "    - separar las clases (clasificación)\n",
    "    - aprender una función simple (regresión)\n",
    "\n",
    "![](https://drive.google.com/uc?id=1AweAOix_IbFbHKnjmj3RYIgHkdGTfrX0)\n",
    "\n",
    "![](https://drive.google.com/uc?id=1v5-eamP3AQ_vxHs4hWelr6lZ_b0vvoDg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehZO5fSZFMdJ"
   },
   "source": [
    "### Optimización basada en gradientes\n",
    "* Vimos que una capa realiza una operación como:\n",
    "``` python\n",
    "y = relu(dot(W, x) + b)\n",
    "```\n",
    "\n",
    "* ¿Cómo encontrar buenos valores para $W$ y $b$ para que los datos se transformen en una representación útil?\n",
    "* Comience con una inicialización aleatoria, luego repita:\n",
    "    1. Saque un un lote (*batch*) de datos de entrenamiento $x$\n",
    "    2. _Forward pass_: ejecutar la red en $x$ para producir $y_{pred}$ (operaciones de tensor)\n",
    "    3. Computar el loss (discrepancia entre $y_{pred}$ e $y$)\n",
    "    4. Actualizar $W$, $b$ de una manera que reduce ligeramente el loss (OK, pero cómo?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5h1-78GnFMdJ"
   },
   "source": [
    "#### Regla de actualización\n",
    "Enfoque ingenuo (caro):\n",
    "* Elija un peso $w_{i, j}$ para optimizar, congele los demás\n",
    "* Ejecute la red (dos veces) con $w_{i,j} - \\epsilon$ y $w_{i,j} + \\epsilon$\n",
    "* Calcule las pérdidas dado el actual batch x\n",
    "* Conserve el que reduzca más la pérdida, luego repita"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suvHGV8gFMdJ"
   },
   "source": [
    "![](https://drive.google.com/uc?id=1BfdkGQBAwmdGAwo9XlsXmzHGxhVP16XA)\n",
    "\n",
    "Mejor:\n",
    "* Elegir una loss function f que sea _diferenciable_\n",
    "    * Además, todas las operaciones de tensores subyacentes deben ser diferenciables\n",
    "* Luego, podemos calcular la derivada $\\frac{\\partial f(x,w_{i,j})}{\\partial w_{i,j}} = a$\n",
    "* Tal que $f(x,w_{i,j} + \\epsilon) = y + a * \\epsilon$\n",
    "* Ahora podemos estimar mejores pesos sin volver a calcular $f$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "koMe8PyWFMdK"
   },
   "source": [
    "#### Gradientes\n",
    "* Un _gradiente_ es la generalización de una derivada a entradas de n-dimensiones\n",
    "    * Aproxima la _curvatura_ de la función de pérdida (loss function) $f(x,W)$ alrededor de un punto dado $W$\n",
    "* Actualización: Si $f$ es diferenciable, entonces $W_1$ = $W_0$ - $\\frac{\\partial f(W_0)}{\\partial W} * step$ \n",
    "    * step es un pequeño factor de escalamiento\n",
    "    * Ir en contra de la curvatura a un lugar más bajo en la curva.\n",
    "* Ahora repita con un nuevo lote de datos $x$\n",
    "\n",
    "![](https://drive.google.com/uc?id=1hjXtfZJLZ28ZXEWzM8WvoWsakkEnaqb-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaSnZWu8FMdK"
   },
   "source": [
    "#### Stochastic gradient descent (SGD)\n",
    "Mini-batch SGD:\n",
    "1. Obtener un lote de *batch_size* datos de entrenamiento $x$ e $y$\n",
    "2. _Forward pass_: correr la red usando $x$ para obtener $y_{pred}$ (operaciones de tensor)\n",
    "3. Computar la pérdida L (desacuerdo entre  $y_{pred}$ e $y$)\n",
    "4. _Backward pass_: Computar el gradiente de la pérdida con respecto a $W$\n",
    "5. Actualizar W: $W_{i+1} = W_i - \\frac{\\partial L(x, W_i)}{\\partial W} * step$\n",
    "\n",
    "Repita hasta que se hagan n pasadas (épocas) a través de todo el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kg2_MiT-FMdK"
   },
   "source": [
    "variantes de SGD:\n",
    "* Batch Gradient Descent: calcular gradiente en todo el conjunto de entrenamiento\n",
    "    - Gradientes más precisos, pero más caros\n",
    "* True Stochastic Gradient Descent: repetir para cada punto de datos individual (ruidoso)\n",
    "* Minibatch SGD logra un equilibrio entre los dos (dado el tamaño de lote correcto)\n",
    "    \n",
    "![](https://drive.google.com/uc?id=1malzKvK1OPTPkAxIAkP_jgQEucKM75S-)\n",
    "\n",
    "![](https://drive.google.com/uc?id=1KnuK6KuXjLhjXWpCVb2O1PZxXhD-tXbN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYy38EZHFMdK"
   },
   "source": [
    "#### SGD: muchas más variantes\n",
    "* Con SGD, es bastante fácil quedar atrapado en un mínimo local\n",
    "* Decaimiento de la tasa de aprendizaje: comenzar con un tamaño de paso grande y luego disminuya\n",
    "* Momentum: hacer una actualización más grande si la actualización anterior tiene una gran mejora en la función de pérdida\n",
    "    - Como una pelota que gana velocidad si baja abruptamente\n",
    "* Tamaño de paso (step) adaptable para cada W_i: adam, Adagrad,...\n",
    "    - Ver https://arxiv.org/pdf/1609.04747.pdf\n",
    "* Algunas intuiciones dicen que en espacios de alta dimensión, la mayoría de los mínimos locales están cerca del mínimo global\n",
    "\n",
    "![](https://drive.google.com/uc?id=1cqEtD48cW4XpOf8Suci6_vufyxlQe3dS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hc06OlXQFMdK"
   },
   "source": [
    "#### Backpropagation\n",
    "* En la práctica, una función de red neuronal consta de muchas operaciones de tensores encadenados\n",
    "    - ej. $f(W1, W2, W3) = a(W1, b(W2, c(W3)))$\n",
    "* Siempre que cada operación tensorial sea diferenciable, aún podemos calcular el gradiente gracias a la regla de la cadena:\n",
    "    $$f(g(x)) = f'(g(x)) * g'(x)$$\n",
    "* Podemos dejar que el gradiente se propague hacia atrás (*backpropagat*) a través de las capas\n",
    "* Entonces, si tenemos un nodo oculto $h(x)=f(W_1 x+b_1)$, $net(x) = W_1 x+b_1$, y un nodo de salida $o(x)=g(W_2 h(x)+b_2)$\n",
    "\n",
    "![](https://drive.google.com/uc?id=1xm-W2BLvEgQZClTu5w5534-PkKA6_bBe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lq8vVJlJFMdK"
   },
   "source": [
    "### Entendiendo $\\frac{\\partial h(x)}{\\partial net(x)}$\n",
    "- Imagina un diablito que agrega un pequeño cambio $\\Delta u_k$ a la entrada de una neurona $k$\n",
    "    - La neurona ahora emite $\\sigma(u_k + \\Delta u_k)$ en vez de $\\sigma(u_k)$\n",
    "    - Se propaga a través de la red, provocando finalmente un error $\\frac{\\delta E}{\\delta u_k} \\Delta u_k$\n",
    "- Un buen diablito te ayuda a mejorar el error al tratar de encontrar un $\\Delta u_k$ que reduce el error\n",
    "    - Si $\\frac{\\delta E}{\\delta u_k}$ es grande, elige $\\Delta u_k$ para reducirlo.\n",
    "\n",
    "![Tampering with the weights creates an error downstream.](https://drive.google.com/uc?id=1Wor3mwz4qcvbzhf3nKU-LUKIi_qQsfkQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AE7lcOXQFMdL"
   },
   "source": [
    "### Backpropagation en acción\n",
    "Para obtener una comprensión intuitiva de cómo backpropagation funciona, aquí hay una bonita animación de todo el proceso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "PIjBI_5cOnaa",
    "outputId": "614eb16b-8700-49bc-e2d9-490c0a5747f7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Ilg3gGewQ5U\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Ilg3gGewQ5U\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8-SVKCiFMdL"
   },
   "source": [
    "#### Diferenciación simbólica y automática\n",
    "Diferenciación simbólica: dada una cadena de operaciones con una derivada conocida, podemos calcular una *función de gradiente* para la cadena\n",
    "* Descompone funciones en funciones más simples mediante la regla de la cadena\n",
    "* Podemos llamar a la función de gradiente para obtener el valor de gradiente para cada parámetro del modelo.\n",
    "\n",
    "Diferenciación automática: evalúe la derivada de una función numéricamente para un cálculo más rápido\n",
    "\n",
    "\n",
    "Las herramientas modernas como TensorFlow hacen esto por uno para que no tengamos que implementar backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOQoKhCuFMdL"
   },
   "source": [
    "### Jugar con redes neuronales\n",
    "\n",
    "\n",
    "http://playground.tensorflow.org\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lS_XJb2SNSqr"
   },
   "source": [
    "### Videos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "zzeIkD5YFMdL",
    "outputId": "00325615-2a96-488e-e577-193dfccb4b77"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Suevq-kZdIw\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Suevq-kZdIw\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "iUyIkgVnBvnC",
    "outputId": "d769df14-6abc-4aee-ed8b-b6bc9e6c91d3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/yRUUDJfDarU\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/yRUUDJfDarU\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
