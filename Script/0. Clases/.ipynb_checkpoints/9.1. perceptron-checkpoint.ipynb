{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FD0RT8vK3Zmd"
   },
   "source": [
    "***\n",
    "\n",
    "Profesor: Gonzalo A. Ruz, PhD\n",
    "\n",
    "Curso: Aprendizaje Automático\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3Y8tt37kl2T"
   },
   "source": [
    "## Implementación del Perceptrón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T18:45:49.347323Z",
     "start_time": "2022-10-04T18:45:49.304889Z"
    },
    "id": "eMXzgst4klIR"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T18:45:51.194848Z",
     "start_time": "2022-10-04T18:45:51.145539Z"
    },
    "id": "AGAMSWHpk-CE"
   },
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "  def __init__(self, N, alpha=0.1):\n",
    "\t\t# inicializar la matriz de pesos y guardar la tasa de aprendizaje\n",
    "    self.W = np.random.randn(N + 1) / np.sqrt(N)\n",
    "    self.alpha = alpha\n",
    "  \n",
    "  def step(self, x):\n",
    "\t\t# aplicar la función escalón\n",
    "    return 1 if x > 0 else 0\n",
    "\n",
    "  def fit(self, X, y, epochs=10):\n",
    "\t\t# inserte una columna de 1s como la última entrada en la \n",
    "    # matriz de características: este pequeño truco nos permite tratar \n",
    "    # el sesgo como un parámetro entrenable dentro de la matriz de peso\n",
    "    X = np.c_[X, np.ones((X.shape[0]))]\n",
    "    # bucle sobre el número deseado de épocas\n",
    "    for epoch in np.arange(0, epochs): #por defecto seteado en 10 épocas\n",
    "      # bucle sobre cada punto de datos individual\n",
    "      for (x, target) in zip(X, y):\n",
    "        # tome el producto punto entre las características\n",
    "        # de entrada y la matriz de peso, luego pase este valor \n",
    "        # a través de la función escalón/umbral para obtener la predicción\n",
    "        p = self.step(np.dot(x, self.W)) #np.dot es el producto punto\n",
    "        # solo realice una actualización de peso si\n",
    "        # nuestra predicción no coincide con el objetivo (target)\n",
    "        if p != target: #si la salida es diferente (!=) al target, debo actualizar los pesos (backpropagation)\n",
    "          # determinar el error\n",
    "          error = p - target\n",
    "          # actualizar la matriz de pesos\n",
    "          self.W += -self.alpha * error * x #el w es igual al error anterior * error\n",
    "          \n",
    "  def predict(self, X, addBias=True):\n",
    "    # asegúrese de que nuestra entrada sea una matriz\n",
    "    X = np.atleast_2d(X)\n",
    "    # verifique si se debe agregar la columna de sesgo\n",
    "    if addBias:\n",
    "      # inserte una columna de 1s como la última entrada\n",
    "      # en la matriz de características (sesgo)\n",
    "      X = np.c_[X, np.ones((X.shape[0]))]\n",
    "      # tome el producto punto entre las características \n",
    "      # de entrada y la matriz de peso, luego pase el valor \n",
    "      # a través de la función escalón\n",
    "    return self.step(np.dot(X, self.W))\n",
    "    \n",
    "  def score(self, X, y): #calculo de un accuracy: total de datos - error / total de datos\n",
    "    misclassified_data_count = 0\n",
    "    for xi, target in zip(X, y):\n",
    "      output = self.predict(xi)\n",
    "      if(target != output):\n",
    "        misclassified_data_count += 1\n",
    "    total_data_count = len(X)\n",
    "    self.score_ = (total_data_count - misclassified_data_count)/total_data_count\n",
    "    return self.score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZErpLGU-pdKj"
   },
   "source": [
    "#### Caso OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T18:50:52.077956Z",
     "start_time": "2022-10-04T18:50:52.059250Z"
    },
    "id": "E2KqgDE-pRuH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training perceptron...\n"
     ]
    }
   ],
   "source": [
    "# construir el conjunto de datos OR\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [1]])\n",
    "\n",
    "# definir nuestro perceptrón y entrenarlo\n",
    "print(\"[INFO] training perceptron...\")\n",
    "p = Perceptron(X.shape[1], alpha=0.1)\n",
    "p.fit(X, y, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T18:51:00.030214Z",
     "start_time": "2022-10-04T18:51:00.002503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.24551845,  0.84349321, -0.07352034])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFPuDWgkqEiy"
   },
   "source": [
    "Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T18:51:01.270657Z",
     "start_time": "2022-10-04T18:51:01.239614Z"
    },
    "id": "OGqRwLz7qGjy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] testing perceptron...\n",
      "[INFO] data=[0 0], ground-truth=0, pred=0\n",
      "[INFO] data=[0 1], ground-truth=1, pred=1\n",
      "[INFO] data=[1 0], ground-truth=1, pred=1\n",
      "[INFO] data=[1 1], ground-truth=1, pred=1\n",
      "Accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora que nuestro perceptrón está entrenado podemos evaluarlo\n",
    "print(\"[INFO] testing perceptron...\")\n",
    "\n",
    "# ahora que nuestra red está entrenada, podemos recorrer los puntos de datos\n",
    "for (x, target) in zip(X, y):\n",
    "\t# hacer una predicción sobre el punto de dato y \n",
    "  # mostrar el resultado en nuestra consola\n",
    "\tpred = p.predict(x)\n",
    "\tprint(\"[INFO] data={}, ground-truth={}, pred={}\".format(\n",
    "\t\tx, target[0], pred))\n",
    "\n",
    "print(\"Accuracy\")\n",
    "p.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xltKnnJryeO"
   },
   "source": [
    "#### Caso AND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T18:52:05.865969Z",
     "start_time": "2022-10-04T18:52:05.845967Z"
    },
    "id": "34cPKyVor7Ta"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training perceptron...\n"
     ]
    }
   ],
   "source": [
    "# construir el conjunto de datos AND\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [0], [0], [1]])\n",
    "# definir nuestro perceptrón y entrenarlo\n",
    "print(\"[INFO] training perceptron...\")\n",
    "p = Perceptron(X.shape[1], alpha=0.1)\n",
    "p.fit(X, y, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLcJ2FpCsLil"
   },
   "source": [
    "Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T18:52:07.348612Z",
     "start_time": "2022-10-04T18:52:07.309900Z"
    },
    "id": "-jKwsvp6sNPA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] testing perceptron...\n",
      "[INFO] data=[0 0], ground-truth=0, pred=0\n",
      "[INFO] data=[0 1], ground-truth=0, pred=0\n",
      "[INFO] data=[1 0], ground-truth=0, pred=0\n",
      "[INFO] data=[1 1], ground-truth=1, pred=1\n",
      "Accuray\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora que nuestro perceptrón está entrenado podemos evaluarlo\n",
    "print(\"[INFO] testing perceptron...\")\n",
    "# ahora que nuestra red está entrenada, podemos recorrer los puntos de datos\n",
    "for (x, target) in zip(X, y):\n",
    "\t# hacer una predicción sobre el punto de dato y \n",
    "  # mostrar el resultado en nuestra consola\n",
    "\tpred = p.predict(x)\n",
    "\tprint(\"[INFO] data={}, ground-truth={}, pred={}\".format(\n",
    "\t\tx, target[0], pred))\n",
    " \n",
    "print(\"Accuray\")\n",
    "p.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYroJtxXuhuQ"
   },
   "source": [
    "#### Caso XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T18:52:12.149664Z",
     "start_time": "2022-10-04T18:52:12.123507Z"
    },
    "id": "fMgh5kIHuncY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training perceptron...\n"
     ]
    }
   ],
   "source": [
    "# construir el conjunto de datos XOR\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0], [1], [1], [0]])\n",
    "# definir nuestro perceptrón y entrenarlo\n",
    "print(\"[INFO] training perceptron...\")\n",
    "p = Perceptron(X.shape[1], alpha=0.1)\n",
    "p.fit(X, y, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOT7zUJOu83x"
   },
   "source": [
    "Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T18:52:15.050928Z",
     "start_time": "2022-10-04T18:52:15.003717Z"
    },
    "id": "Q2_5TNx0u_wM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] testing perceptron...\n",
      "[INFO] data=[0 0], ground-truth=0, pred=1\n",
      "[INFO] data=[0 1], ground-truth=1, pred=0\n",
      "[INFO] data=[1 0], ground-truth=1, pred=0\n",
      "[INFO] data=[1 1], ground-truth=0, pred=0\n",
      "Accuray\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora que nuestro perceptrón está entrenado podemos evaluarlo\n",
    "print(\"[INFO] testing perceptron...\")\n",
    "# ahora que nuestra red está entrenada, podemos recorrer los puntos de datos\n",
    "for (x, target) in zip(X, y):\n",
    "\t# hacer una predicción sobre el punto de dato y \n",
    "  # mostrar el resultado en nuestra consola\n",
    "\tpred = p.predict(x)\n",
    "\tprint(\"[INFO] data={}, ground-truth={}, pred={}\".format(\n",
    "\t\tx, target[0], pred))\n",
    "\n",
    "print(\"Accuray\")\n",
    "p.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xb8hZf8_vboh"
   },
   "source": [
    "## Veamos un dataset más complejo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T18:53:23.626465Z",
     "start_time": "2022-10-04T18:53:16.518529Z"
    },
    "id": "MGmmCRHfvg3O"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9005847953216374, 0.9195979899497487)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "# Cargar el dataset\n",
    "#\n",
    "bc = datasets.load_breast_cancer()\n",
    "X = bc.data\n",
    "y = bc.target\n",
    "#\n",
    "# Crear división de entrenamiento y prueba\n",
    "#\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "#\n",
    "# Crear una instancia de Perceptron\n",
    "#\n",
    "prcptrn = Perceptron(X_train.shape[1], alpha=0.1)\n",
    "#\n",
    "# entrenamiento\n",
    "#\n",
    "prcptrn.fit(X_train, y_train,epochs=20)\n",
    "#\n",
    "# Accuracy en test y train\n",
    "#\n",
    "prcptrn.score(X_test, y_test), prcptrn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rdMIOrRzMD9"
   },
   "source": [
    "## Podríamos usar el perceptrón de Scikit-learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T18:56:15.748286Z",
     "start_time": "2022-10-04T18:56:15.046260Z"
    },
    "id": "gd0i6a4NzlSL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.895\n",
      "Accuracy: 0.895\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar el dataset\n",
    "#\n",
    "bc = datasets.load_breast_cancer()\n",
    "X = bc.data\n",
    "y = bc.target\n",
    "#\n",
    "# Crear división de entrenamiento y prueba\n",
    "#\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "ppn = Perceptron(eta0=0.1, random_state=1) #eta es el alfa, con esto se genera el modelo\n",
    "ppn.fit(X_train, y_train)\n",
    " \n",
    "y_pred = ppn.predict(X_test)\n",
    " \n",
    "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))\n",
    "print('Accuracy: %.3f' % ppn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MVkKCXB-19ih"
   },
   "source": [
    "## Iris dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T18:58:57.029526Z",
     "start_time": "2022-10-04T18:58:56.989317Z"
    },
    "id": "LwKjwHZNzE2y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.956\n",
      "Accuracy: 0.956\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y)\n",
    " \n",
    "sc = StandardScaler() #standarizacion\n",
    "sc.fit(X_train) #aprender la media y desv standar (para eso es el fit)\n",
    "X_train_std = sc.transform(X_train) #standarizamos el train\n",
    "X_test_std = sc.transform(X_test) #standarizamos el test\n",
    " \n",
    "ppn = Perceptron(eta0=0.1, random_state=1)\n",
    "ppn.fit(X_train_std, y_train)\n",
    " \n",
    "y_pred = ppn.predict(X_test_std)\n",
    " \n",
    "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))\n",
    "print('Accuracy: %.3f' % ppn.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
